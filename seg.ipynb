{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T09:56:54.552271104Z",
     "start_time": "2024-02-02T09:56:51.064256949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang.ming/miniconda3/envs/detr-playground/lib/python3.10/site-packages/transformers/models/segformer/feature_extraction_segformer.py:28: FutureWarning: The class SegformerFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use SegformerImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b5 and are newly initialized: ['decode_head.linear_fuse.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.2.proj.bias', 'decode_head.classifier.bias', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.batch_norm.weight', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.2.proj.weight', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.0.proj.bias', 'decode_head.classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/mit-b5\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b5\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image_url = \"https://cdn-media.huggingface.co/Inference-API/Sample-results-on-the-Cityscapes-dataset-The-above-images-show-how-our-method-can-handle.png\"\n",
    "example_image = Image.open(requests.get(example_image_url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cityscapes_labels = [\n",
    "    \"road\", \"sidewalk\", \"building\", \"wall\", \"fence\", \n",
    "    \"pole\", \"traffic light\", \"traffic sign\", \"vegetation\", \"terrain\",\n",
    "    \"sky\", \"person\", \"rider\", \"car\", \"truck\", \n",
    "    \"bus\", \"train\", \"motorcycle\", \"bicycle\"\n",
    "]\n",
    "colors = np.random.randint(0, 255, size=(len(cityscapes_labels), 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 607 is out of bounds for axis 0 with size 19",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m mask_np \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Create an RGB image for each class (you might need to customize this part based on the number of classes and desired colors)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# random 14 colors : np.array([[0, 0, 0], ...]) for each class\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m seg_image \u001b[38;5;241m=\u001b[39m \u001b[43mcolors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_np\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Overlay (this can be adjusted to change the transparency or the way of overlaying)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m \u001b[38;5;241m*\u001b[39m image_np \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.001\u001b[39m \u001b[38;5;241m*\u001b[39m seg_image\n",
      "\u001b[0;31mIndexError\u001b[0m: index 607 is out of bounds for axis 0 with size 19"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "# image = example_image\n",
    "image = Image.open(\"./datasets/Das3300161.jpg\")\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)\n",
    "\n",
    "\n",
    "# Overlay the mask on the original image\n",
    "# Convert original image to numpy array and normalize it\n",
    "image_np = np.array(image) / 255.0\n",
    "\n",
    "# Apply softmax and argmax to get the most likely class for each pixel\n",
    "probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "mask = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "# Resize mask to the size of the original image\n",
    "mask = F.resize(mask.unsqueeze(1), size=image_np.shape[:2], interpolation=F.InterpolationMode.NEAREST).squeeze()\n",
    "\n",
    "# Convert mask to numpy array for visualization\n",
    "mask_np = mask.detach().cpu().numpy()\n",
    "\n",
    "# Create an RGB image for each class (you might need to customize this part based on the number of classes and desired colors)\n",
    "# random 14 colors : np.array([[0, 0, 0], ...]) for each class\n",
    "\n",
    "seg_image = colors[mask_np]\n",
    "\n",
    "# Overlay (this can be adjusted to change the transparency or the way of overlaying)\n",
    "combined = 0.7 * image_np + 0.001 * seg_image\n",
    "\n",
    "# Create a subplot: 1 row, 3 columns\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original image\n",
    "axs[0].imshow(image_np)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Segmentation mask\n",
    "axs[1].imshow(seg_image)\n",
    "axs[1].set_title('Segmentation Mask')\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Combined image\n",
    "axs[2].imshow(combined)\n",
    "axs[2].set_title('Overlay Image')\n",
    "axs[2].axis('off')\n",
    "\n",
    "# filter label in output include in cityscapes_labels\n",
    "unique_labels = np.unique(mask_np)\n",
    "\n",
    "# Add the legend to the last subplot, convert colors to 0-1\n",
    "patches = [mpatches.Patch(color=colors[i]/255.0, label=cityscapes_labels[i]) for i in range(len(cityscapes_labels)) if i in unique_labels]\n",
    "axs[2].legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "# Display the subplot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'building', 'car', 'crack', 'dog', 'litter', 'pavement', 'truck', 'tyer'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "datasets_dir = \"/Users/famer.me/Repository/crack-in-asphalt/2023-12-04/Origin/1\"\n",
    "\n",
    "labels = [\n",
    "\tfile for file in os.listdir(datasets_dir) if file.endswith(\".json\")\n",
    "]\n",
    "\n",
    "images = [\n",
    "\tfile[0:-5] + \".jpg\" for file in labels\n",
    "]\n",
    "\n",
    "list(zip(labels, images))\n",
    "\n",
    "labels_json = [\n",
    "\tjson.load(open(os.path.join(datasets_dir, label), \"r\")) for label in labels\n",
    "]\n",
    "\n",
    "set([\n",
    "\tshape[\"label\"]\n",
    "\tfor label_json in labels_json\n",
    "\tfor shape in label_json[\"shapes\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['version', 'flags', 'shapes', 'imagePath', 'imageData', 'imageHeight', 'imageWidth'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_json[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T09:57:02.586540914Z",
     "start_time": "2024-02-02T09:57:02.397540900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "processor = SegformerImageProcessor.from_pretrained('mingyang91/segformer-for-surveillance', do_reduce_labels=True)\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"mingyang91/segformer-for-surveillance\").to('mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from segformer_trainer import downsample_image_pil, polygons_to_mask, split_image_into_tiles, split_mask_into_tiles\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "basedir = 'datasets/segformer/val'\n",
    "test = 'Das1100051.json'\n",
    "scale_factor = 4.0\n",
    "\n",
    "ann_path = os.path.join(basedir, test)\n",
    "img_path = os.path.join(basedir, test.replace('.json', '.jpg'))\n",
    "\n",
    "# Load image\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "image = downsample_image_pil(image, scale_factor=scale_factor)\n",
    "image = np.array(image)\n",
    "\n",
    "# Load annotation and create mask\n",
    "with open(ann_path) as f:\n",
    "    anns = json.load(f)\n",
    "for shape in anns['shapes']:\n",
    "    if shape['shape_type'] == 'polygon':\n",
    "        shape['points'] = [[int(p[0] / scale_factor), int(p[1] / scale_factor)] for p in shape['points']]\n",
    "mask = polygons_to_mask(image.shape[:2], anns['shapes'])\n",
    "\n",
    "tiles = split_image_into_tiles(image)\n",
    "\n",
    "# Optionally split the mask here in the same way if training\n",
    "masks = split_mask_into_tiles(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# all_image_tiles = [processor(images=item, return_tensors=\"pt\")['pixel_values'].squeeze() for item in tiles]\n",
    "# all_mask_tiles = [torch.as_tensor(item, dtype=torch.long) for item in masks]\n",
    "\n",
    "# # Stack the selected tensors to create batches\n",
    "# images_stacked = torch.stack(all_image_tiles).to('mps')\n",
    "# masks_stacked = torch.stack(all_mask_tiles).to('mps')\n",
    "inputs = processor(images=tiles, segmentation_maps=masks, return_tensors=\"pt\").to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0629, -0.0458, -0.0629,  ..., -0.1314, -0.1486, -0.1657],\n",
       "          [-0.0801, -0.0801, -0.0629,  ..., -0.1486, -0.1486, -0.1657],\n",
       "          [-0.1143, -0.0801, -0.0629,  ..., -0.0972, -0.1486, -0.1143],\n",
       "          ...,\n",
       "          [-0.2342, -0.2171, -0.2171,  ..., -0.5253, -0.5253, -0.5253],\n",
       "          [-0.2513, -0.2513, -0.3027,  ..., -0.5596, -0.5424, -0.5253],\n",
       "          [-0.2684, -0.2684, -0.2171,  ..., -0.4911, -0.5082, -0.4911]],\n",
       "\n",
       "         [[-0.4951, -0.4776, -0.4951,  ..., -0.4076, -0.4251, -0.4426],\n",
       "          [-0.5126, -0.5126, -0.4951,  ..., -0.4251, -0.4251, -0.4426],\n",
       "          [-0.5476, -0.5126, -0.4951,  ..., -0.3725, -0.4251, -0.3901],\n",
       "          ...,\n",
       "          [-0.4426, -0.4251, -0.4251,  ..., -0.6352, -0.6352, -0.6352],\n",
       "          [-0.4601, -0.4601, -0.5126,  ..., -0.6702, -0.6527, -0.6352],\n",
       "          [-0.4776, -0.4776, -0.4426,  ..., -0.6001, -0.6176, -0.6001]],\n",
       "\n",
       "         [[-0.6715, -0.6541, -0.6715,  ..., -0.4624, -0.4624, -0.4973],\n",
       "          [-0.6890, -0.6890, -0.6715,  ..., -0.4798, -0.4798, -0.4973],\n",
       "          [-0.7238, -0.6890, -0.6715,  ..., -0.4624, -0.4973, -0.4798],\n",
       "          ...,\n",
       "          [-0.4624, -0.4450, -0.4450,  ..., -0.5670, -0.5670, -0.5670],\n",
       "          [-0.4798, -0.4798, -0.5321,  ..., -0.6018, -0.5844, -0.5670],\n",
       "          [-0.4973, -0.4973, -0.4624,  ..., -0.5321, -0.5495, -0.5321]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2282,  0.2111,  0.1768,  ..., -0.4739, -0.4911, -0.4054],\n",
       "          [ 0.2453,  0.2111,  0.2111,  ..., -0.4739, -0.4226, -0.4226],\n",
       "          [ 0.2453,  0.2282,  0.1939,  ..., -0.4739, -0.4739, -0.4568],\n",
       "          ...,\n",
       "          [-0.5767, -0.6109, -0.6281,  ...,  0.2111,  0.3652,  0.3309],\n",
       "          [-0.5767, -0.5767, -0.6109,  ...,  0.1597,  0.3138,  0.2967],\n",
       "          [-0.5424, -0.5938, -0.5596,  ...,  0.1597,  0.3481,  0.2282]],\n",
       "\n",
       "         [[-0.2325, -0.2500, -0.2850,  ..., -0.6001, -0.6176, -0.5301],\n",
       "          [-0.2150, -0.2500, -0.2500,  ..., -0.6001, -0.5476, -0.5476],\n",
       "          [-0.2500, -0.2675, -0.3025,  ..., -0.6001, -0.6001, -0.5826],\n",
       "          ...,\n",
       "          [-0.6702, -0.6877, -0.7052,  ..., -0.3550, -0.3200, -0.3725],\n",
       "          [-0.6527, -0.6527, -0.6877,  ..., -0.4251, -0.3200, -0.3725],\n",
       "          [-0.6176, -0.6702, -0.6352,  ..., -0.4426, -0.2850, -0.4251]],\n",
       "\n",
       "         [[-0.4450, -0.4624, -0.4973,  ..., -0.5321, -0.5495, -0.4624],\n",
       "          [-0.4275, -0.4624, -0.4624,  ..., -0.5321, -0.4798, -0.4798],\n",
       "          [-0.4450, -0.4624, -0.4973,  ..., -0.5321, -0.5321, -0.5147],\n",
       "          ...,\n",
       "          [-0.5495, -0.5670, -0.5844,  ..., -0.5670, -0.4973, -0.5495],\n",
       "          [-0.5321, -0.5321, -0.5670,  ..., -0.6367, -0.5844, -0.6541],\n",
       "          [-0.4973, -0.5495, -0.5147,  ..., -0.6541, -0.5495, -0.7064]]],\n",
       "\n",
       "\n",
       "        [[[-0.6109, -0.6281, -0.6281,  ..., -1.1418, -1.0390, -0.6281],\n",
       "          [-0.5938, -0.5938, -0.5767,  ..., -1.1589, -1.0562, -0.4911],\n",
       "          [-0.5596, -0.5596, -0.5767,  ..., -1.1589, -0.8849, -0.4054],\n",
       "          ...,\n",
       "          [ 0.3823,  0.3652,  0.3823,  ...,  0.3994,  0.4508,  0.3994],\n",
       "          [ 0.3994,  0.3823,  0.3994,  ...,  0.3994,  0.3994,  0.3994],\n",
       "          [ 0.3994,  0.3652,  0.3994,  ...,  0.3994,  0.3823,  0.3823]],\n",
       "\n",
       "         [[-0.7227, -0.7402, -0.7402,  ..., -1.2829, -1.2129, -0.9328],\n",
       "          [-0.7052, -0.7052, -0.6877,  ..., -1.3179, -1.2479, -0.7927],\n",
       "          [-0.7052, -0.7052, -0.6527,  ..., -1.3704, -1.0903, -0.6352],\n",
       "          ...,\n",
       "          [-0.2500, -0.2675, -0.2500,  ..., -0.2325, -0.1800, -0.2325],\n",
       "          [-0.2325, -0.2500, -0.2325,  ..., -0.2150, -0.2325, -0.2325],\n",
       "          [-0.2325, -0.2675, -0.2325,  ..., -0.2325, -0.2500, -0.2500]],\n",
       "\n",
       "         [[-0.6367, -0.6541, -0.6541,  ..., -1.1770, -1.1596, -0.9678],\n",
       "          [-0.6193, -0.6193, -0.6018,  ..., -1.2119, -1.1944, -0.8284],\n",
       "          [-0.5844, -0.6018, -0.5844,  ..., -1.2293, -1.0550, -0.7238],\n",
       "          ...,\n",
       "          [-0.4973, -0.5147, -0.4973,  ..., -0.4798, -0.4275, -0.4798],\n",
       "          [-0.4798, -0.4973, -0.4798,  ..., -0.4275, -0.4450, -0.4450],\n",
       "          [-0.4798, -0.5147, -0.4798,  ..., -0.4450, -0.4624, -0.4624]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.3369, -0.0972, -0.0458,  ..., -0.9363, -0.9877, -0.9192],\n",
       "          [-0.1314,  0.0227, -0.0116,  ..., -0.5767, -0.6965, -0.1657],\n",
       "          [ 0.1768,  0.0398,  0.0741,  ..., -0.0116,  0.1254,  0.1939],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
       "\n",
       "         [[-0.7052, -0.5126, -0.5301,  ..., -1.2654, -1.3004, -1.2479],\n",
       "          [-0.6527, -0.4951, -0.5126,  ..., -0.9853, -1.1078, -0.5651],\n",
       "          [-0.3901, -0.5301, -0.4951,  ..., -0.5301, -0.3901, -0.3375],\n",
       "          ...,\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       "\n",
       "         [[-0.8633, -0.6890, -0.7413,  ..., -1.2467, -1.2816, -1.2293],\n",
       "          [-0.7587, -0.6541, -0.7064,  ..., -1.0898, -1.2119, -0.6890],\n",
       "          [-0.5844, -0.7413, -0.7064,  ..., -0.7587, -0.6193, -0.5670],\n",
       "          ...,\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3652,  0.2967,  0.1083,  ...,  0.3138,  0.2624,  0.2796],\n",
       "          [ 0.2967,  0.2967,  0.1597,  ...,  0.3138,  0.3138,  0.2967],\n",
       "          [ 0.3309,  0.2624,  0.0912,  ...,  0.3138,  0.3309,  0.2796],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
       "\n",
       "         [[-0.3200, -0.3725, -0.5126,  ..., -0.3200, -0.3901, -0.3550],\n",
       "          [-0.3901, -0.3725, -0.4776,  ..., -0.3375, -0.3375, -0.3550],\n",
       "          [-0.3725, -0.4251, -0.5826,  ..., -0.3375, -0.3200, -0.3725],\n",
       "          ...,\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       "\n",
       "         [[-0.5495, -0.6018, -0.7587,  ..., -0.4798, -0.5321, -0.5147],\n",
       "          [-0.6193, -0.6018, -0.7238,  ..., -0.4798, -0.4798, -0.4973],\n",
       "          [-0.6018, -0.6541, -0.8110,  ..., -0.5147, -0.4973, -0.5321],\n",
       "          ...,\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2453,  0.2282,  0.3309,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [ 0.2796,  0.2796,  0.3309,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [ 0.2967,  0.2624,  0.2282,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
       "\n",
       "         [[-0.3550, -0.3725, -0.3200,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-0.3200, -0.3200, -0.3025,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-0.3550, -0.3725, -0.4251,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          ...,\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       "\n",
       "         [[-0.5495, -0.5670, -0.4973,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-0.5147, -0.5147, -0.4798,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-0.5321, -0.5495, -0.6018,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          ...,\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 3, 512, 512])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.pixel_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0')]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from segformer_trainer import id2label\n",
    "import torch.nn.functional as F\n",
    "\n",
    "with torch.no_grad():\n",
    "\toutputs = model(**inputs)\n",
    "target_sizes = [(inputs.pixel_values.shape[2], inputs.pixel_values.shape[3])] * inputs.pixel_values.shape[0]\n",
    "seg_result = processor.post_process_semantic_segmentation(outputs, target_sizes=target_sizes)\n",
    "print(seg_result)\n",
    "seg_result = seg_result[0].cpu().numpy()\n",
    "print(seg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[-0.0629, -0.0629, -0.1314,  ...,  0.6049,  0.6392,  0.6392],\n",
       "          [-0.0801, -0.0629, -0.0801,  ...,  0.6221,  0.7077,  0.6906],\n",
       "          [-0.0801, -0.0629, -0.0801,  ...,  0.5022,  0.6049,  0.7248],\n",
       "          ...,\n",
       "          [-0.3541, -0.3369, -0.3712,  ..., -0.0116, -0.0287, -0.0287],\n",
       "          [-0.3712, -0.3369, -0.3712,  ..., -0.0287, -0.0116, -0.0287],\n",
       "          [-0.3369, -0.3369, -0.3883,  ..., -0.0458, -0.0116,  0.0056]],\n",
       "\n",
       "         [[-0.4951, -0.4951, -0.5301,  ...,  0.6604,  0.7129,  0.6954],\n",
       "          [-0.5126, -0.4951, -0.4951,  ...,  0.6954,  0.7654,  0.7304],\n",
       "          [-0.5126, -0.5126, -0.5126,  ...,  0.4678,  0.6078,  0.7304],\n",
       "          ...,\n",
       "          [-0.7227, -0.6877, -0.7227,  ..., -0.5126, -0.5476, -0.5476],\n",
       "          [-0.7227, -0.6877, -0.7227,  ..., -0.5301, -0.5301, -0.5476],\n",
       "          [-0.7402, -0.7227, -0.7402,  ..., -0.5301, -0.5126, -0.5126]],\n",
       "\n",
       "         [[-0.6715, -0.6541, -0.6367,  ...,  1.1411,  1.2108,  1.1934],\n",
       "          [-0.6890, -0.6715, -0.6715,  ...,  1.0539,  1.1934,  1.2108],\n",
       "          [-0.6890, -0.6715, -0.6890,  ...,  0.7576,  0.9145,  1.0714],\n",
       "          ...,\n",
       "          [-0.7761, -0.7587, -0.7936,  ..., -0.6367, -0.6541, -0.6367],\n",
       "          [-0.7936, -0.7761, -0.7936,  ..., -0.6541, -0.6541, -0.6541],\n",
       "          [-0.8284, -0.7936, -0.8110,  ..., -0.6541, -0.6367, -0.6541]]]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = processor(images=image, labels=mask, return_tensors=\"pt\", size=(1024,1024), do_reduce_labels=True)\n",
    "inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
